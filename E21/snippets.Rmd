---
title: "Basic statistics for health research - snippets"
author: "Benjamin Skov Kaas-Hansen"
date: "19/2/2021"
output: 
  html_document: 
    code_folding: show
    df_print: tibble
    highlight: haddock
    theme: paper
    toc: yes
    toc_depth: 3
---

### Brief intro and R quirks
There are some things to be aware of when using R (or any other programming language) and knowing how R behaves and handles certain situations can help you find errors in your code. Don't lose hope! It seems irrelevant but can save you hours of debugging or googling mysterious error messagges, in the long run.

```{r}
library(tidyverse)

# Sequences
c(1, 2, 3, 4, 5, 6)
1:6
seq(1, 6) # seq() allows for more elaborate sequences when needed, see ?seq

# Vectorised computations, vectors are repeated which can give incorrect results
c(1, 2, 3, 4, 5, 6) * 2 # element-wise (many x 1)
c(1, 2, 3, 4, 5, 6) * c(1, 1, 2, 2) # repeats the second vector 1.5 times (gives a warning, though)
c(1, 2, 3, 4, 5, 6) * c(1, 2, 3) # repeated the second vector twice, then element-wise
log(c(1, 2, 3, 4, 5, 6)) # element-wise

# Strings vs. numbers
x <- "2"
y <- 2
try(x * 2) # error, it's not a number (I have to put it inside try() so the error doesn't hault the script)
y * 2 # all good, it's a number

x <- c("1", "22", "3", "2", "10")
y <- c(1, 22, 3, 2, 10)
sort(x) # start from the beginning of the word (so, "10" comes before "2")
sort(y) # knows that these are numbers, so sorting is correct
parse_number(x) %>% # nifty function from the readr package to numbers written as strings to actual numbers
	sort() 
```

#### Piping
At its core, R is a so-called functional programming language. This just means that the everything you do is based on the use of functions. A function takes one input (sometimes more), does something with that input, and spits out the result. You can often affect what the function does with the other arguments (e.g. `na.rm` in `mean` ensures that missing values (`NA`s in R) are ignored.) This can be depicted like this:

```{r, out.width="75%", echo=FALSE, fig.align="center"}
knitr::include_graphics("../figures/functions.png")
```

Knowing that the *first* argument of the function is usually the input (be it a vector, dataframe or a single value) is important to exploit the so-called pipe operator. The pipe (`%>%`; Mac: cmd + shit + M, Windows: ctrl + shift + M) takes the output from the function (or directly an object, e.g. a dataframe or vector) on its left-hand side and uses that as the *first* input to it function on its right-hand side. The new version of R actually has a built-in pipe operator that behaves the same way (there are differences but we won't get into those here.) Usually you add a newline after the pipe to give the code some structure (and you'll see that Rstudio automatically indents the next line to aid the eye):
```{r}
library(tidyverse)

x <- c(1, 2, 3, 4, 5, 6, NA)
x %>% 
	mean(na.rm = TRUE)

# is the same as
mean(x, na.rm = TRUE)

# is the same as
c(1, 2, 3, 4, 5, 6, NA) %>% 
	mean(na.rm = TRUE)
```

In this particular example, the pipe isn't all that useful, but even slightly more involved manipulation can make the code a lot more readable (and, thus, less prone to errors):
```{r}
x <- c(1, 2, 3, 4, 5, 6, NA)
x %>% 
	na.exclude() %>% 
	log() %>% 
	mean()

# is the same as
mean(log(na.exclude(x)), na.rm = TRUE)
```

Brevity should never hurt clarity, so it's better to write longer code which is easier to read and understand. Especially for data analytics where your target reader is unlikely to be an experienced programmer.

#### Missing data
In R missing data are represented by `NA`, and you must use the function `is.na()` to find `NA`'s; it's an error to try e.g. `x == NA` because something cannot be equal to something that isn't there. Even two things that aren't there cannot be compared because there's no logical way to do that.
```{r}
NA == NA # gives NA
is.na(NA) # gives TRUE
!TRUE # gives FALSE because the exclamation negates TRUE/FALSE statements in R
!c(TRUE, FALSE, TRUE, FALSE) # they become opposite
!is.na(NA) 
!is.na(x) # all except the last are not NA
x[!is.na(x)] # pick only the values that aren't NA
```

#### `dplyr`
`dplyr` is built around a number of function with meaningful verb names, each with a specific purpose in data manipulation. First, a dummy data frame for the example:
```{r}
d <- data.frame(x = c(1, 2, 3, 4, 5, 6), 
				y = c("a", "b", "c", "c", "b", "a"))
```

Then the verbs:
```{r}
# mutate() changes the columns or adds new ones; doesn't change the number of rows
d %>% 
	mutate(z = x * 2) # add new column based exisiting column(s)
d %>% 
	mutate(x = x * 2, # overwrites the x column in place
		   z = x * 2) # so the z column is now actually: x * 2 * 2

# transmute() works like mutate() but only retains column modified
d %>% 
	transmute(z = x * 2)

d %>% 
	transmute(x, # just putting the variable there keeps the variable as-is if no modification needed
			  z = x * 2)

# rename()
d %>% 
	rename(new_x = x)

d %>% 
	rename(new_x = x,
		   new_y = y)

# select() does what it sounds like, it selects columns
d %>% 
	select(y)

d %>% 
	select(-x) # use a minus to remove columns

d %>% # let's build a little chain of manipulations
	mutate(z = x * 2) %>% 
	select(x, z)

d %>% 
	mutate(z = x * 2,
		   u = log(z)) %>% 
	select(y:u) # use colon for a range of column names without writing each of them

d %>% 
	select(new_x = x, # you can also rename while selecting
		   y) 

# filter() allows you to keep only rows that satisfy certain criteria
d %>% 
	filter(y == "b") # use the double equal sign for matching with one value

d %>% 
	filter(y %in% c("b", "c")) # and %in% if the column can have several values

d %>% 
	filter(x > 3,
		   y == "b") # empty data frame because no results satisfy both criteria

d %>% 
	filter(x == 1 | y == "b") # the vertial line is a logic OR, so rows satisfying any of the criteria are kept

d %>% 
	filter(between(x, 1, 3)) # keeps rows in which the x value is in the range [1, 3] (so bounds included)

d %>% 
	mutate(z = x * 2) %>% 
	filter(y %in% c("b", "c")) %>% 
	select(x, z)

# arrange() sorts the data by any number of columns
d %>% 
	arrange(x, y) # same as d, becaue sorting happens from the left

d %>% 
	arrange(y, x)

d %>% 
	arrange(desc(x)) # desc() causes sorting in descending order

# summarise() reduces the data frame (or group) to 1 row (it has more flexible use that we ignore for now)
d %>% 
	summarise(mean_x = mean(x)) # only columns that are summarised remain

d %>% 
	summarise(mean_x = mean(x),
			  sd_x = sd(x)) # you can compute several summaries of the same column

d %>% 
	mutate(z = x * 2) %>% 
	summarise(mean_x = mean(x),
			  sd_x = sd(x),
			  mean_y = mean(z),
			  sd_z = sd(z),
			  median_z = median(z)) # and you can summarise any number of columns

# group_by() splits the dataframe into groups by column values, behind the scenes (so to you it will look the same)
d %>% 
	group_by(y)

d %>% 
	group_by(y) %>% 
	summarise(mean_x = mean(x)) # summarise gives group-wise summaries (ignore the warning)
```

The salient point is that, with the `dplyr` verbs and the pipe (`%>%`) you can make chains as long as you need them to be. Data frames are so-called immutable so the `d` dataframe is the same as we defined in the very top of the code before, because all these little pipe chains aren't saved anywhere. 
```{r}
d

d_new <- d %>% 
	mutate(z = x * 2) %>% 
	filter(y %in% c("b", "c")) %>% 
	select(x, z)

d # d remains
d_new # but the chain result is now saved in d_new

d <- d %>% 
	mutate(z = x * 2) %>% 
	filter(y %in% c("b", "c")) %>% 
	select(x, z)

d # now we have ovewritten the old d with the chain result
```

### Add mean to boxplot
```{r}
library(tidyverse)

vit <- read_csv("http://publicifsv.sund.ku.dk/~sr/BasicStatistics/datasets/vitamin.csv") %>% 
	mutate(country = factor(country, levels = c(1, 2, 4, 6), labels = c("DK", "SF", "EI", "PL")))

ggplot(vit, aes(x = country, y = vitd)) +
	geom_boxplot() +
	stat_summary(fun = mean, geom = "point", size = 4, colour = "dodgerblue", shape = "diamond")
```

### Cross-tabulations of contingency table with test statistics
Note the warning about the approximation (sone expected counts <5), so use Fisher's test instead.
```{r}
library(descr)

# Create toy data
cont_table <- matrix(c(3, 10, 8, 14), nrow = 2,
                     dimnames = list(arm = c("active", "control"), outcome = c("yes", "no")))

CrossTable(cont_table, expected = TRUE, chisq = TRUE, fisher = TRUE, format = "SPSS") 
```

